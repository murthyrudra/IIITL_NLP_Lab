{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHECRIFh8ZRO"
      },
      "source": [
        "# Lab 09\n",
        "\n",
        "In this lab, we will try to use the OpenNMT library to train an NMT model using the toy English-German dataset.\n",
        "\n",
        "This notebook was found originally at:\n",
        "https://github.com/OpenNMT/OpenNMT-py#quickstart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CClOS9iT1Fsp"
      },
      "outputs": [],
      "source": [
        "# Install OpenNMT-py 2.x\n",
        "# NOTE: By the end of the insatallation, it might ask for restarting the runtime...\n",
        "# In this case, just click the \"RESTART RUNTIME\" button.\n",
        "\n",
        "!pip3 install git+https://github.com/OpenNMT/OpenNMT-py.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "Esz4fKZRGVvx",
        "outputId": "3ce72f9a-f1f6-4404-84d9-91dd13feffac"
      },
      "outputs": [],
      "source": [
        "# On Google Colab ONLY\n",
        "# Reinstall Torch to avoid incompatibility with Cuda 10.1\n",
        "\n",
        "# NOTE: By the end of the insatallation, it might ask for restarting the runtime...\n",
        "# In this case, just click the \"RESTART RUNTIME\" button.\n",
        "\n",
        "!pip3 install --ignore-installed torch==1.6.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj-PhnzqzMBQ",
        "outputId": "394888fe-7058-4a3e-c807-6a4c275d4dc4"
      },
      "outputs": [],
      "source": [
        "# Download the files of the QuickStart\n",
        "\n",
        "!wget https://s3.amazonaws.com/opennmt-trainingdata/toy-ende.tar.gz\n",
        "!tar xf toy-ende.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7oLWNaPZ_3m",
        "outputId": "f7592733-c927-4b75-ff05-80cd561a1285"
      },
      "outputs": [],
      "source": [
        "# Optional: List the extracted files\n",
        "\n",
        "!cd toy-ende/ && ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUxHPm8izhzJ",
        "outputId": "f84c42eb-d203-4ca0-96cb-8d86780e726f"
      },
      "outputs": [],
      "source": [
        "# Optional: Print the first 3 lines of the source file\n",
        "\n",
        "!head -n 3 toy-ende/src-train.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOXCYqXOM9un",
        "outputId": "99d1b14c-a847-46b9-cbf0-53962f8efdc4"
      },
      "outputs": [],
      "source": [
        "# Optional: Check the number of lines in the source file\n",
        "\n",
        "!echo \"Number of lines:\" && wc -l toy-ende/src-train.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jgYJhuzzh96",
        "outputId": "29f20aff-26d1-47c7-f848-9f562ca38942"
      },
      "outputs": [],
      "source": [
        "# Create the YAML configuration file\n",
        "# On a regular machine, you can create it manually or with nano\n",
        "\n",
        "config = '''# toy_en_de.yaml\n",
        "\n",
        "## Where the samples will be written\n",
        "save_data: toy-ende/run/example\n",
        "\n",
        "## Where the vocab(s) will be written\n",
        "src_vocab: toy-ende/run/example.vocab.src\n",
        "tgt_vocab: toy-ende/run/example.vocab.tgt\n",
        "\n",
        "## Where the model will be saved\n",
        "save_model: model/model\n",
        "\n",
        "# Prevent overwriting existing files in the folder\n",
        "overwrite: False\n",
        "\n",
        "# Corpus opts:\n",
        "data:\n",
        "    corpus_1:\n",
        "        path_src: toy-ende/src-train.txt\n",
        "        path_tgt: toy-ende/tgt-train.txt\n",
        "    valid:\n",
        "        path_src: toy-ende/src-val.txt\n",
        "        path_tgt: toy-ende/tgt-val.txt\n",
        "\n",
        "world_size: 1\n",
        "gpu_ranks: [0]\n",
        "\n",
        "# Remove or modify these lines for bigger files\n",
        "train_steps: 1000\n",
        "valid_steps: 200\n",
        "'''\n",
        "\n",
        "with open(\"toy_en_de.yaml\", \"w+\") as config_yaml:\n",
        "  config_yaml.write(config)\n",
        "\n",
        "!cat toy_en_de.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRMJGSan8FoF",
        "outputId": "0ce08dc0-1e48-4a1b-ff64-f997b671b4ad"
      },
      "outputs": [],
      "source": [
        "# Build Vocabulary\n",
        "\n",
        "!onmt_build_vocab -config toy_en_de.yaml -n_sample -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRMNMIBzziDs",
        "outputId": "3d13e450-6374-4fe7-ea88-ff3832bce925"
      },
      "outputs": [],
      "source": [
        "# Check if GPU is active\n",
        "# If not, go to \"Runtime\" menu > \"Change runtime type\" > \"GPU\"\n",
        "\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhpACn0WFQgG",
        "outputId": "057b59fc-ee13-42fe-ccaa-c926c10232fa"
      },
      "outputs": [],
      "source": [
        "# Make sure the GPU is visable to PyTorch\n",
        "\n",
        "import torch\n",
        "\n",
        "gpu_id = torch.cuda.current_device()\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(gpu_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6mgFwEX90UP",
        "outputId": "4895952c-708a-460e-c33d-4fe89489e47d"
      },
      "outputs": [],
      "source": [
        "# Train the NMT model\n",
        "\n",
        "!onmt_train -config toy_en_de.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQtKJduoXCz7"
      },
      "outputs": [],
      "source": [
        "# Translate\n",
        "\n",
        "!onmt_translate -model model/model_step_1000.pt -src toy-ende/src-test.txt -output toy-ende/pred_1000.txt -gpu 0 -verbose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uWerf-6pqsm"
      },
      "source": [
        "Install Sacrebleu to evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLET3PKMpvdD",
        "outputId": "8ac4f17a-d40c-4e28-b69e-c9ce5a5300b8"
      },
      "outputs": [],
      "source": [
        "!pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX6CfM3WVVz7",
        "outputId": "e728be77-822a-46dc-baaf-060dcc5a8ace"
      },
      "outputs": [],
      "source": [
        "!sacrebleu toy-ende/tgt-test.txt < toy-ende/pred_1000.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " #### A1 \n",
        "  - Please note down the BLEU scores obtained above in the cell below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* (note down results here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### A2 \n",
        "\n",
        " - Your assginment is to train a model using the OpenNMT library as shown above but with larger dataset.\n",
        "\n",
        " - You can use any parallel corpus available from [Samanantar](https://indicnlp.ai4bharat.org/samanantar/)\n",
        "\n",
        " - Train a model on a single language pair and evaluate it using BLEU score as a metric as shown above.\n",
        "\n",
        " - Also note down the hyperparameters used for training the model. \n",
        "\n",
        " - As a class you can discuss amongst yourselves and can collectively try different hyperparameters. \n",
        "\n",
        " - If the parallel corpus is hard to fit in the GPU memory then you can use a smaller dataset, but if you are collectively trying different hyperparameters then all of you should experiment with the same dataset.\n",
        "\n",
        " - (Optional) You can further try to byte-pair encode the corpus and re-train the model. [The byte-pair encoding code is available in this notebook.](https://github.com/cfiltnlp/IITB-English-Hindi-PC/blob/main/IITB_En_Hi_Get_Data.ipynb) This notebook contains the code for byte-pair encoding the [IITB-English Hindi Parallel Corpus](https://huggingface.co/datasets/cfilt/iitb-english-hindi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "OpenNMT-py QuickStart IIITL Lab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
